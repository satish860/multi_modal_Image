{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b18ecf36-2be3-46cd-8cc0-a9707abac623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d81594f-d361-4027-8198-5841622507ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddeb8e6-1405-458c-8f0e-6f4207b49970",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e522ec9-438d-4d24-8cf5-b6ec06d5cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "330798ae-93cd-4aed-adab-470825222a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-02 12:22:00,256 : INFO : loading projection weights from /home/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2021-06-02 12:22:49,233 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /home/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2021-06-02T12:22:49.233471', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0d1b66a-6b88-4073-828f-c5e01c177eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/3000000 is </s>\n",
      "word #1/3000000 is in\n",
      "word #2/3000000 is for\n",
      "word #3/3000000 is that\n",
      "word #4/3000000 is is\n",
      "word #5/3000000 is on\n",
      "word #6/3000000 is ##\n",
      "word #7/3000000 is The\n",
      "word #8/3000000 is with\n",
      "word #9/3000000 is said\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de04e662-7d3c-4b6f-b75a-4064aba19a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c4daab-f110-4a9d-8911-5d34d20affa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "King - man + woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164ccf52-cd6b-44b1-a4c6-b465899c301c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"king\",\"woman\"],negative=[\"man\"],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8092a8b-ea32-4059-bb60-75b3da957208",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e47f69-04a0-46a3-8078-60dcd6a44d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    ('car', 'minivan'),   # a minivan is a kind of car\n",
    "    ('car', 'bicycle'),   # still a wheeled vehicle\n",
    "    ('car', 'airplane'),  # ok, no wheels, but still a vehicle\n",
    "    ('car', 'cereal'),    # ... and so on\n",
    "    ('car', 'communism'),\n",
    "]\n",
    "for w1, w2 in pairs:\n",
    "    print('%r\\t%r\\t%.2f' % (w1, w2, wv.similarity(w1, w2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6cdd79-7d85-4a47-b051-3837ffe6499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(positive=[\"car\",\"minivan\"],topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853991c-d81d-41e8-ab5d-0e03f4db1f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.doesnt_match(['fire', 'water', 'land', 'sea', 'air', 'car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f30787-a534-4495-b0dd-069d5891bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9387f9-3dc4-4891-810f-9204870d608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('lee_background.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261e1e4-21e6-4427-a75f-5ca67444b35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c6359e-7ee6-499b-bad1-d199756e2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298964ef-a180-4825-af80-beadb040d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(positive=['happy', 'family'],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dfa1d6-9c33-4d9d-b069-873204b415c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.most_similar(positive=[vec], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81cbe71-c267-4cbe-aebf-bfcaef493594",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = 'InstaNY100K/captions/newyork/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d69b45-10da-42a1-9489-24ebe19db3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c144d8-1ea8-4f8b-a7bd-19bf72e68b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir(corpus_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00045be6-3113-4883-a501-867f58d2911b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "for file in files:\n",
    "    for line in open(f'{corpus_path}{file}'):\n",
    "        print(utils.simple_preprocess(line))\n",
    "    break;\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "022cd738-ce98-4e2f-8d51-f538c0b79816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "string_with_nonASCII = \"àa string withé fuünny charactersß879.\"\n",
    "\n",
    "encoded_string = string_with_nonASCII.encode(\"ascii\", \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "007ddb15-40b9-422a-8855-97171c19184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a string with funny characters.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st=encoded_string.decode()\n",
    "st_nodigits=''.join([i for i in st if not i.isdigit()])\n",
    "st_nodigits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfa46bc2-6433-4786-8e8c-235302a900c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48e30439-828f-4286-a9fd-8fe08e7cae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string,strip_non_alphanum,strip_numeric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0b9975d-c663-45af-beb1-4d2ea2adf37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file in files:\n",
    "            for line in open(f'{corpus_path}{file}'):\n",
    "                CUSTOM_FILTERS = [lambda x: x.lower(), remove_stopwords, strip_non_alphanum,strip_numeric]\n",
    "                yield preprocess_string(line,CUSTOM_FILTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8d61002-fec5-4d36-9dad-e1b6142d23c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 15:15:29,144 : INFO : collecting all words and their counts\n",
      "2021-06-01 15:15:29,147 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-06-01 15:15:29,850 : INFO : PROGRESS: at sentence #10000, processed 267788 words, keeping 56519 word types\n",
      "2021-06-01 15:15:30,510 : INFO : PROGRESS: at sentence #20000, processed 530302 words, keeping 91817 word types\n",
      "2021-06-01 15:15:31,161 : INFO : PROGRESS: at sentence #30000, processed 788353 words, keeping 120367 word types\n",
      "2021-06-01 15:15:31,823 : INFO : PROGRESS: at sentence #40000, processed 1048316 words, keeping 146653 word types\n",
      "2021-06-01 15:15:32,465 : INFO : PROGRESS: at sentence #50000, processed 1298676 words, keeping 168875 word types\n",
      "2021-06-01 15:15:33,119 : INFO : PROGRESS: at sentence #60000, processed 1551339 words, keeping 189182 word types\n",
      "2021-06-01 15:15:33,770 : INFO : PROGRESS: at sentence #70000, processed 1799261 words, keeping 207705 word types\n",
      "2021-06-01 15:15:34,383 : INFO : PROGRESS: at sentence #80000, processed 2031570 words, keeping 224655 word types\n",
      "2021-06-01 15:15:35,014 : INFO : PROGRESS: at sentence #90000, processed 2273032 words, keeping 242083 word types\n",
      "2021-06-01 15:15:35,694 : INFO : collected 259132 word types from a corpus of 2541970 raw words and 100000 sentences\n",
      "2021-06-01 15:15:35,695 : INFO : Creating a fresh vocabulary\n",
      "2021-06-01 15:15:35,950 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 43338 unique words (16.724294953923096%% of original 259132, drops 215794)', 'datetime': '2021-06-01T15:15:35.950353', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2021-06-01 15:15:35,951 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2225436 word corpus (87.54768939051208%% of original 2541970, drops 316534)', 'datetime': '2021-06-01T15:15:35.951562', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2021-06-01 15:15:36,208 : INFO : deleting the raw counts dictionary of 259132 items\n",
      "2021-06-01 15:15:36,214 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2021-06-01 15:15:36,215 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2087017.1233247758 word corpus (93.8%% of prior 2225436)', 'datetime': '2021-06-01T15:15:36.215510', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2021-06-01 15:15:36,642 : INFO : estimated required memory for 43338 words and 100 dimensions: 56339400 bytes\n",
      "2021-06-01 15:15:36,643 : INFO : resetting layer weights\n",
      "2021-06-01 15:15:36,701 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-06-01T15:15:36.701251', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'build_vocab'}\n",
      "2021-06-01 15:15:36,702 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 43338 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-06-01T15:15:36.702512', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2021-06-01 15:15:37,722 : INFO : EPOCH 1 - PROGRESS: at 7.77% examples, 168348 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:38,757 : INFO : EPOCH 1 - PROGRESS: at 16.11% examples, 170785 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:39,767 : INFO : EPOCH 1 - PROGRESS: at 24.11% examples, 170285 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:40,813 : INFO : EPOCH 1 - PROGRESS: at 32.89% examples, 170847 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:41,832 : INFO : EPOCH 1 - PROGRESS: at 41.16% examples, 171930 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:42,835 : INFO : EPOCH 1 - PROGRESS: at 49.95% examples, 173340 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:43,861 : INFO : EPOCH 1 - PROGRESS: at 58.72% examples, 173771 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:44,885 : INFO : EPOCH 1 - PROGRESS: at 67.77% examples, 175279 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:45,918 : INFO : EPOCH 1 - PROGRESS: at 77.10% examples, 175153 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:46,927 : INFO : EPOCH 1 - PROGRESS: at 86.22% examples, 174613 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:47,935 : INFO : EPOCH 1 - PROGRESS: at 94.67% examples, 175883 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:48,546 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-01 15:15:48,550 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-01 15:15:48,563 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-01 15:15:48,565 : INFO : EPOCH - 1 : training on 2541970 raw words (2087037 effective words) took 11.9s, 176015 effective words/s\n",
      "2021-06-01 15:15:49,611 : INFO : EPOCH 2 - PROGRESS: at 8.16% examples, 171732 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:50,620 : INFO : EPOCH 2 - PROGRESS: at 16.11% examples, 170630 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:51,625 : INFO : EPOCH 2 - PROGRESS: at 24.11% examples, 170590 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:52,636 : INFO : EPOCH 2 - PROGRESS: at 32.53% examples, 170429 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:53,653 : INFO : EPOCH 2 - PROGRESS: at 40.36% examples, 170105 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:54,673 : INFO : EPOCH 2 - PROGRESS: at 48.72% examples, 170000 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:55,692 : INFO : EPOCH 2 - PROGRESS: at 57.16% examples, 169916 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:56,703 : INFO : EPOCH 2 - PROGRESS: at 65.39% examples, 170090 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:57,748 : INFO : EPOCH 2 - PROGRESS: at 75.01% examples, 171308 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:58,773 : INFO : EPOCH 2 - PROGRESS: at 84.55% examples, 171704 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:15:59,776 : INFO : EPOCH 2 - PROGRESS: at 93.53% examples, 174016 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:00,484 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-01 15:16:00,488 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-01 15:16:00,507 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-01 15:16:00,509 : INFO : EPOCH - 2 : training on 2541970 raw words (2087183 effective words) took 11.9s, 174820 effective words/s\n",
      "2021-06-01 15:16:01,522 : INFO : EPOCH 3 - PROGRESS: at 8.16% examples, 177191 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:02,546 : INFO : EPOCH 3 - PROGRESS: at 16.87% examples, 180058 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:03,576 : INFO : EPOCH 3 - PROGRESS: at 25.66% examples, 180858 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:04,621 : INFO : EPOCH 3 - PROGRESS: at 34.74% examples, 180686 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:05,633 : INFO : EPOCH 3 - PROGRESS: at 43.59% examples, 181686 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:06,655 : INFO : EPOCH 3 - PROGRESS: at 52.73% examples, 182257 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:07,702 : INFO : EPOCH 3 - PROGRESS: at 61.77% examples, 182104 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:08,726 : INFO : EPOCH 3 - PROGRESS: at 71.13% examples, 182438 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:09,756 : INFO : EPOCH 3 - PROGRESS: at 80.66% examples, 181639 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:10,770 : INFO : EPOCH 3 - PROGRESS: at 89.72% examples, 181132 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:11,810 : INFO : EPOCH 3 - PROGRESS: at 98.54% examples, 182041 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:11,955 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-01 15:16:11,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-01 15:16:11,971 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-01 15:16:11,973 : INFO : EPOCH - 3 : training on 2541970 raw words (2086710 effective words) took 11.5s, 182100 effective words/s\n",
      "2021-06-01 15:16:13,005 : INFO : EPOCH 4 - PROGRESS: at 8.16% examples, 173952 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:14,022 : INFO : EPOCH 4 - PROGRESS: at 16.49% examples, 175125 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:15,047 : INFO : EPOCH 4 - PROGRESS: at 24.86% examples, 175243 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:16,064 : INFO : EPOCH 4 - PROGRESS: at 33.28% examples, 173691 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:17,107 : INFO : EPOCH 4 - PROGRESS: at 41.57% examples, 173362 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:18,119 : INFO : EPOCH 4 - PROGRESS: at 49.95% examples, 172935 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:19,119 : INFO : EPOCH 4 - PROGRESS: at 58.34% examples, 172888 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:20,164 : INFO : EPOCH 4 - PROGRESS: at 66.94% examples, 173032 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:21,188 : INFO : EPOCH 4 - PROGRESS: at 76.29% examples, 173305 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:22,230 : INFO : EPOCH 4 - PROGRESS: at 85.84% examples, 173234 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:23,231 : INFO : EPOCH 4 - PROGRESS: at 94.26% examples, 174708 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:23,861 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-01 15:16:23,865 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-01 15:16:23,881 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-01 15:16:23,882 : INFO : EPOCH - 4 : training on 2541970 raw words (2086863 effective words) took 11.9s, 175293 effective words/s\n",
      "2021-06-01 15:16:24,932 : INFO : EPOCH 5 - PROGRESS: at 8.53% examples, 178728 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:25,946 : INFO : EPOCH 5 - PROGRESS: at 16.87% examples, 177767 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:26,951 : INFO : EPOCH 5 - PROGRESS: at 25.27% examples, 178141 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:27,996 : INFO : EPOCH 5 - PROGRESS: at 34.01% examples, 176693 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:29,023 : INFO : EPOCH 5 - PROGRESS: at 42.78% examples, 177949 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:30,053 : INFO : EPOCH 5 - PROGRESS: at 51.54% examples, 177487 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:31,084 : INFO : EPOCH 5 - PROGRESS: at 60.23% examples, 177330 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:32,123 : INFO : EPOCH 5 - PROGRESS: at 69.02% examples, 176984 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:33,126 : INFO : EPOCH 5 - PROGRESS: at 78.03% examples, 176324 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:34,172 : INFO : EPOCH 5 - PROGRESS: at 87.46% examples, 175865 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:35,207 : INFO : EPOCH 5 - PROGRESS: at 95.88% examples, 176607 words/s, in_qsize 0, out_qsize 0\n",
      "2021-06-01 15:16:35,689 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-06-01 15:16:35,690 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-06-01 15:16:35,704 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-06-01 15:16:35,705 : INFO : EPOCH - 5 : training on 2541970 raw words (2087134 effective words) took 11.8s, 176586 effective words/s\n",
      "2021-06-01 15:16:35,707 : INFO : Word2Vec lifecycle event {'msg': 'training on 12709850 raw words (10434927 effective words) took 59.0s, 176854 effective words/s', 'datetime': '2021-06-01T15:16:35.706924', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2021-06-01 15:16:35,708 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=43338, vector_size=100, alpha=0.025)', 'datetime': '2021-06-01T15:16:35.708472', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caaf0f2a-af19-4ecf-8884-cdafc4b88d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43338"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274aa7fd-c4cb-45d5-ae48-f03531e2c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "model.wv.evaluate_word_analogies(datapath('questions-words.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ef58aa6-ae2d-443d-874e-38d4aa6b3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "508cad5c-b2ae-4a32-961e-8eec8d5b5fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0/43338 is newyork\n",
      "word #1/43338 is nyc\n",
      "word #2/43338 is love\n",
      "word #3/43338 is fashion\n",
      "word #4/43338 is newyorkcity\n",
      "word #5/43338 is new\n",
      "word #6/43338 is london\n",
      "word #7/43338 is s\n",
      "word #8/43338 is paris\n",
      "word #9/43338 is manhattan\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index}/{len(wv.index_to_key)} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a57146be-7ca1-429b-baeb-6367efe044f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('friendship', 0.8211256861686707),\n",
       " ('bestfriend', 0.8104841709136963),\n",
       " ('sisters', 0.7777823209762573),\n",
       " ('bestfriends', 0.7758079767227173),\n",
       " ('friends', 0.7688908576965332),\n",
       " ('sister', 0.7564769983291626),\n",
       " ('boyfriend', 0.7389432787895203),\n",
       " ('fun', 0.7271031141281128),\n",
       " ('laugh', 0.7251623272895813),\n",
       " ('holiday', 0.7221683859825134)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=[\"happy\",\"family\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef38670b-33e7-41e2-9c3e-69d321a0758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-01 15:25:01,432 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'gensim-model-100k', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-06-01T15:25:01.431957', 'gensim': '4.0.1', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.4.0-72-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2021-06-01 15:25:01,434 : INFO : not storing attribute cum_table\n",
      "2021-06-01 15:25:01,526 : INFO : saved gensim-model-100k\n"
     ]
    }
   ],
   "source": [
    "model.save('gensim-model-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc44762e-0c61-4d65-90f7-a2814ac6f298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
